{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/root/mutimedia_final/data/df1.csv\")\n",
    "save_path = \"/root/mutimedia_final/result/sentiment_result_2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                微博正文  \\\n",
      "0  新浪娱乐:【17-24时要闻回顾】俞灏明回应魏晨结婚时送房：原谅我当年的年少无知http:/...   \n",
      "1  Cinderellapp月小昱:刚看了一集《探世界》 瞬间穿越回到旧金山 唐人街 干货店 粤...   \n",
      "2  有新欢如何成功挽回前男友:女生在提出分手的时候，很多人会说对你彻底失望了，我要分手但有些是内...   \n",
      "3  科技阿康:#iOS13.5正式版推送#为了面对疫情，苹果正式推送了iOS13.5正式版的更新...   \n",
      "4  泰娱乐论坛:#泰娱乐论坛热门泰剧# 【泰剧《倒霉女孩 / 珍贵的坏运气》人物剧照欣赏（第二部...   \n",
      "\n",
      "                                           tokenized  \n",
      "0  新浪 娱乐 : 【 17 - 24 时 要闻 回顾 】 俞灏明 回应 魏晨 结婚 时送 房 ...  \n",
      "1  Cinderellapp 月 小昱 : 刚看 了 一集 《 探 世界 》   瞬间 穿越 回...  \n",
      "2  有 新欢 如何 成功 挽回 前男友 : 女生 在 提出 分手 的 时候 ， 很多 人会 说 ...  \n",
      "3  科技 阿康 : # iOS13.5 正式版 推送 # 为了 面对 疫情 ， 苹果 正式 推送...  \n",
      "4  泰 娱乐 论坛 : # 泰 娱乐 论坛 热门 泰剧 #   【 泰剧 《 倒霉 女孩   /...  \n"
     ]
    }
   ],
   "source": [
    "test_df['tokenized'] = test_df['微博正文'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "test_df.to_csv('/root/mutimedia_final/result/tokenized_1.csv', index=False) \n",
    "print(test_df[['微博正文', 'tokenized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and tokenizer\n",
    "model_path = '/root/mutimedia_final/saved_models/epochs_8' \n",
    "model_name = 'bert-base-chinese'\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "test_texts = test_df['微博正文'].tolist()\n",
    "\n",
    "# Tokenize the test data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Convert to Dataset object\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/mech/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           微博id         发布者昵称 发布者性别 发布者地区  发布者关注数   发布者粉丝数  \\\n",
      "0     ItwJSk2JW        南郑检察微博     男    陕西     900     3099   \n",
      "1     ItwJP5Qu0  __Gumusservi     女    上海     107       21   \n",
      "2     ItwJP5RVK       愉善坊自家果园     女    上海      53       54   \n",
      "3     ItwJNCk5g          武强视界     男    河北     210     2938   \n",
      "4     ItwJKkRsP          平安淳化     女    陕西     545     1129   \n",
      "...         ...           ...   ...   ...     ...      ...   \n",
      "4856  IqFvigurT         我不是区长     男    浙江    1211    13818   \n",
      "4857  IqFvc33nz         科学未来人     男    上海     979  1869763   \n",
      "4858  IqFuKfOJM         财经新媒体     男    北京     411  1831840   \n",
      "4859  IqFuzB9D8     保定市中级人民法院     女    河北     650   239334   \n",
      "4860  IqFuzl2np          杨幂翻我     女    其他     714    11624   \n",
      "\n",
      "                                                   微博正文                 发布时间  \\\n",
      "0     南郑检察微博:【武汉，莫慌！我们共同战疫！】在疫情防控阻击战面前，中国的医务工作者第一时间冲...  2020-02-10 10:59:00   \n",
      "1     __Gumusservi:#保险杠急救中心[超话]# 打榜抽5000元爱豆代言产品，我正在#...  2020-02-10 10:59:00   \n",
      "2     愉善坊自家果园:国家有难  支援武汉！今天一大早  8点30分大家就集合  准备摘果每户农家...  2020-02-10 10:59:00   \n",
      "3     武强视界:http://t.cn/A6hPM5WC【河北第五批，星夜驰援！】2月9日晚，河北...  2020-02-10 10:59:00   \n",
      "4     平安淳化:#淳化公安防疫在一线# 【家属送温暖，同心协力战疫情】自疫情防控工作开展以来，警察...  2020-02-10 10:59:00   \n",
      "...                                                 ...                  ...   \n",
      "4856  我不是区长:【#鼠年全家福# 之猫】鼠年到，把猫养得肥肥的，鼠是不是就很欢快了不过鼠也不能太...  2020-01-22 15:47:00   \n",
      "4857  科学未来人:#广东新确诊9例新型肺炎病例#累计算下，广东已经有26感染了。广州、深圳、佛山、...  2020-01-22 15:47:00   \n",
      "4858  财经新媒体:【钟南山：武汉病患数量无任何隐瞒】 武汉市互联网信息办公室官方微博援引相关视频表...  2020-01-22 15:46:00   \n",
      "4859  保定市中级人民法院:【#新型冠状肺炎病毒来源是野生动物#】中国科学院院士、中国疾病预防控制中...  2020-01-22 15:46:00   \n",
      "4860  杨幂翻我:#儿童年轻人对病毒不易感#我觉得这个不易敏感可能是年轻气盛抵抗力比较强一点吧，不过...  2020-01-22 15:46:00   \n",
      "\n",
      "      点赞数  转发数  评论数          来源文件  predictions  \n",
      "0       3    0    0  对口支援2.10.csv            4  \n",
      "1       0    0    0  对口支援2.10.csv            2  \n",
      "2       0    0    0  对口支援2.10.csv            2  \n",
      "3       0    0    0  对口支援2.10.csv            4  \n",
      "4       1    0    0  对口支援2.10.csv            4  \n",
      "...   ...  ...  ...           ...          ...  \n",
      "4856   11   26    7   人传人1.20.csv            2  \n",
      "4857  126    2   17   人传人1.20.csv            2  \n",
      "4858   15    1    1   人传人1.20.csv            2  \n",
      "4859    0    0    0   人传人1.20.csv            0  \n",
      "4860    3    0    0   人传人1.20.csv            0  \n",
      "\n",
      "[4861 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(model=model)\n",
    "\n",
    "# Perform predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to labels (if necessary)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Add predictions to the original dataframe\n",
    "test_df['predictions'] = preds\n",
    "\n",
    "# Save the dataframe with predictions\n",
    "test_df.to_csv(save_path, index=False)  # replace with the actual path to save the predictions\n",
    "\n",
    "# Print the dataframe with predictions\n",
    "print(test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
